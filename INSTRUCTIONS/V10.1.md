# V10.1: OMR Rhythm Semantics & Post-Processing

## Tavoite
Korjata Audiveriksen rytmi-semantiikan ongelmat post-processing -kerroksella.

**Kriittinen mittari:** `voice excess` -virheet → 0, measure duration = time signature

---

## Ongelma (V10)

Audiveris tuottaa MusicXML:n, mutta:
- ⚠️ `No timeOffset for HeadChordInter` (rytmi-epävarmuus)
- ⚠️ `Voice excess too long` (nuottien kesto > tahtilaji)
- ⚠️ `no correct rhythm` (aikarakenne epäluotettava)

**Juurisyy:** Audiveris ei pysty sitomaan symboleja ajallisesti ilman vahvaa ankkurointia (time signature, clef, key).

---

## Gate A: Preflight 2 - Structural Anchoring

### A1: Time Signature Detection/Hint

**Tavoite:** Antaa Audiverikselle aikakehys ennen OMR:ää.

```python
def detect_time_signature_hint(image: np.ndarray, header_region: np.ndarray) -> str | None:
    """
    Detect time signature from header region (OCR + symbol detection).
    
    Returns:
        Time signature string (e.g., "4/4", "6/8") or None
    """
    # 1. OCR header for text patterns: "4/4", "6/8", "C" (common time)
    # 2. Symbol detection: Look for time signature symbols
    # 3. Default: "4/4" if not found
```

**Integraatio:**
- Tallenna hint Audiverikselle (config file tai CLI param)
- Tai: Lisää metadata → Audiveris käyttää sitä

### A2: Clef-Forced Anchoring

**Tavoite:** Lukitse clef ensimmäiselle järjestelmälle.

```python
def detect_clef_hint(staff_region: np.ndarray) -> str | None:
    """
    Detect clef from first staff system.
    
    Returns:
        "G" (treble), "F" (bass), "C" (alto/tenor), or None
    """
    # Symbol detection: G-clef, F-clef patterns
    # Default: "G" (treble) if not found
```

### A3: Key Signature Smoothing

**Tavoite:** Ensimmäinen kelvollinen key lukitaan koko järjestelmälle.

```python
def smooth_key_signature(measures: list[Measure]) -> list[Measure]:
    """
    Propagate first valid key signature to all measures.
    """
    first_key = None
    for m in measures:
        if m.key_signature:
            first_key = m.key_signature
            break
    
    if first_key:
        for m in measures:
            if not m.key_signature:
                m.key_signature = first_key
```

### DoD Gate A:
- [ ] Time signature hint detected/assigned
- [ ] Clef hint detected/assigned
- [ ] Key signature smoothed across measures
- [ ] Hints passed to Audiveris (config or metadata)

---

## Gate B: Post-Processing - Rhythm Normalization

### B1: Measure Duration Validation

**Tavoite:** Varmista että tahdin nuottien summa = tahtilaji.

```python
def validate_measure_duration(measure: Measure) -> tuple[bool, float, float]:
    """
    Validate measure duration against time signature.
    
    Returns:
        (is_valid, expected_beats, actual_beats)
    """
    expected = parse_time_signature(measure.time_signature)  # e.g., 4.0 for 4/4
    actual = sum(note.duration_beats for note in measure.notes)
    return (abs(expected - actual) < 0.01, expected, actual)
```

### B2: Voice Excess Correction

**Tavoite:** Korjaa "voice excess" -virheet automaattisesti.

**Strategiat:**

1. **Merge overlapping notes:**
   ```python
   if note1.end_time > note2.start_time:
       # Overlap detected → merge or adjust
   ```

2. **Split long notes:**
   ```python
   if note.duration_beats > measure.remaining_beats:
       # Split note at measure boundary
   ```

3. **Normalize beat positions:**
   ```python
   # Snap notes to grid (e.g., 0.25 beat increments)
   note.beat_position = round(note.beat_position * 4) / 4
   ```

### B3: Time Offset Reconstruction

**Tavoite:** Laske puuttuvat `timeOffset` -arvot.

```python
def reconstruct_time_offsets(measure: Measure) -> Measure:
    """
    Calculate beat positions for notes without timeOffset.
    """
    current_beat = 0.0
    for note in measure.notes:
        if note.beat_position is None:
            note.beat_position = current_beat
        current_beat += note.duration_beats
    return measure
```

### DoD Gate B:
- [ ] Measure duration validation runs on all measures
- [ ] Voice excess errors corrected (merge/split/normalize)
- [ ] Time offsets reconstructed where missing
- [ ] Output: `music.json` with corrected rhythm data

---

## Gate C: QA v2 - Rhythm Validation

### C1: Rhythm QA Rules

```python
def check_rhythm_quality(omr_result: OMRResult) -> list[Finding]:
    """
    Validate rhythm semantics.
    """
    findings = []
    
    for measure in omr_result.measures:
        # Check duration
        valid, expected, actual = validate_measure_duration(measure)
        if not valid:
            findings.append(Finding(
                severity="error",
                message=f"Measure {measure.number}: duration mismatch "
                       f"(expected {expected}, got {actual})"
            ))
        
        # Check for overlapping notes
        overlaps = find_overlapping_notes(measure.notes)
        if overlaps:
            findings.append(Finding(
                severity="warning",
                message=f"Measure {measure.number}: {len(overlaps)} overlapping notes"
            ))
    
    return findings
```

### C2: QA Status Matrix (Updated)

| Condition | Status |
|-----------|--------|
| `omr.success=true`, `measure_count>0`, no rhythm errors | PASS |
| `omr.success=true`, `measure_count>0`, rhythm warnings | PASS (with warnings) |
| `omr.success=true`, `measure_count>0`, rhythm errors | FAIL |
| `omr.success=false` (despite preflight) | FAIL |

### DoD Gate C:
- [ ] Rhythm QA rules implemented
- [ ] QA reports rhythm errors/warnings
- [ ] Status matrix updated
- [ ] `qa_report.json` includes rhythm findings

---

## Gate D: Integration & Testing

### D1: Full Pipeline Test

```bash
# Test with 7x7.jpg
python -m src.pipeline.run_all --image data/00_input/Testidata\ nuottisivu/7x7.jpg

# Verify:
# - Preflight 2: time/clef/key hints applied
# - Post-processing: rhythm normalized
# - QA: no rhythm errors
```

### D2: Output Validation

- [ ] `music.json` contains corrected rhythm data
- [ ] All measures: `duration_beats` = time signature
- [ ] All notes: `beat_position` present
- [ ] QA status = PASS (no rhythm errors)

### DoD Gate D:
- [ ] Full pipeline test passes
- [ ] Rhythm errors corrected
- [ ] QA reports PASS
- [ ] Documentation updated

---

## Tehtävälista (Cursor)

### Vaihe 1: Preflight 2
1. [ ] Implement `detect_time_signature_hint()`
2. [ ] Implement `detect_clef_hint()`
3. [ ] Implement `smooth_key_signature()`
4. [ ] Pass hints to Audiveris (config/metadata)
5. [ ] Test: Verify hints applied

### Vaihe 2: Post-Processing
6. [ ] Implement `validate_measure_duration()`
7. [ ] Implement `correct_voice_excess()` (merge/split/normalize)
8. [ ] Implement `reconstruct_time_offsets()`
9. [ ] Integrate into `parse_musicxml()`
10. [ ] Test: Verify rhythm corrections

### Vaihe 3: QA v2
11. [ ] Implement `check_rhythm_quality()`
12. [ ] Update QA status matrix
13. [ ] Integrate into `run_music_qa()`
14. [ ] Test: Verify QA reports

### Vaihe 4: Integration
15. [ ] Full pipeline test
16. [ ] Verify output quality
17. [ ] Update documentation
18. [ ] Update `docs/dod.md`

---

## Timeline Estimate

| Gate | Effort | Dependency |
|------|--------|------------|
| A: Preflight 2 | 2-3h | - |
| B: Post-Processing | 3-5h | Gate A |
| C: QA v2 | 1-2h | Gate B |
| D: Integration | 1h | Gate C |

**Total: 7-11 hours**

---

## Success Criteria

**V10.1 Complete When:**
- ✅ Preflight 2: Time/clef/key hints applied
- ✅ Post-processing: Rhythm normalized (no voice excess)
- ✅ QA: No rhythm errors (warnings OK)
- ✅ Output: All measures have correct duration
- ✅ Output: All notes have beat positions

**This moves the project from:**
- "Symbol recognition OK → Rhythm semantics FAIL"
- **To:**
- "Symbol recognition OK → Rhythm semantics OK"
